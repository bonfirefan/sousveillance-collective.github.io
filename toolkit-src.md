<link rel="icon" type="image/png" href="http://www.coveillance.org/eyes.png">
<title>surveillance toolkit</title>

<!-- <link rel="stylesheet" href="https://acdlite.github.io/jquery.sidenotes/css/main.css"> -->

<!-- https://tscanlin.github.io/tocbot/ -->
<!-- <link rel="stylesheet" href="https://tscanlin.github.io/tocbot/static/css/styles.css" class="next-head"> -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">

<link rel="stylesheet" href="styles/toolkit-styles.css" class="next-head">

<div class="mw7 center dark-gray lh-copy all-content">

<nav class="toc toc-right js-toc relative z-1 transition--300 absolute pa4 is-position-fixed">
</nav>

<div class="content js-toc-content pa4">

# A people's guide to surveillance

**Note: this material is a work in progress.**

## Why are we making this toolkit? Who's it for?

We're creating a people's guide to surveillance. What we're making is not a book but, we hope, the start of a conversation. By offering our expertise on *how to spot and question the practice of surveillance in daily life*, we're providing scaffolding for community organizers to use to facilitate their own surveillance workshops. The goal is that these workshops would serve as openings for readers and participants to offer us your lived experiences, and for us to work together to develop a shared understanding of how to change the practice of surveillance.

What do we mean by the _practice_ of surveillance? For us, spotting the practice of surveillance means learning to see the _ways of thinking_ that groups of people have used to justify controlling other groups of people over the years, as well as the _tools_, old and new, that people have always used to shape and reshape the balance of power between groups of people. 

<!-- TODO: maybe 'grasping the tools' as in both the ways of thinking and the technologies...? -->

Our material aims to start conversations that throw light on how this ongoing struggle for control is continuing to unfold in our lives and communities today. We hope these conversations can plant the seeds for new ways of thinking and talking about the practice of surveillance, and we want our work to support existing and new movements to make more equitable and transparent the norms, laws, and tools that govern our behavior.

Because surveillance touches everyone, we're trying to write our material to offer something to everyone. If you're a community organizer, technologist, legislator, or interested layperson, we hope you'll find our work useful, or even consider helping us write it or bringing it to your communities.

Included in this toolkit are

* **the written material**, including teaching, learning, and conversation-starting material for community organizers to facilitate surveillance identification workshops,
* **the walking tour**, an overview of surveillance infrastructure in Seattle,
* **the field guide**, a birdwatching-style booklet showing how to spot surveillance infrastructure in daily life, and
* **a map of the anatomy of surveillance**, a poster visualizing relationships between parts of the massive surveillance apparatus, to be collaboratively created by workshop participants.

(The name of our work is inspired by [_A People's Guide to AI_](https://www.alliedmedia.org/peoples-ai).)

## Notes to the instructor

It's hard to get a grasp on surveillance and privacy. It's a huge topic with deep social, historical, and technical dimensions that also impacts our lives from second to second. Governments and companies have incentives to hide how it works. And it changes fast—it seems like some catastrophic new development happens every day. It's hard to find clear information.

There are many excellent single resources out there for learning about surveillance and privacy—various books, whitepapers, pieces of software, news articles, visualizations, and technical guides. We aim to knit existing resources together into a living toolkit that community members can adapt for their own use. Specifically, we aim to fill the timely need for accessible, comprehensive, experience-focused teaching and learning material for building a high-level and technically-sound understanding of surveillance.

Our goal is that you can use our material to get a group of people from “I'm scared” or “why should I care?” to “I understand why this stuff matters, I understand the context of any new news I see, I know what to do to make things safer for myself, and I know where to look to find further reading on the topics I'm interested in.”

The material aims to be short and memorable, so it centers on a question-and-answer approach that incorporates case studies, narratives, illustrations, bullet points, openings for conversation and collaboration, and practical exercises.

The material aims to address participants' pressing personal questions about surveillance as well as contextual questions. Here are the personal questions it addresses:

* Why should I care about surveillance?
* How am I being surveilled?
* How am I surveilling?
* How does surveillance affect me?
* What kind of privacy can I expect from the status quo?
* How should I think about surveillance?
* How should I respond to mainstream surveillance narratives?
* What steps can I take to protect my privacy?
* What can I do about surveillance?
* How can I learn more about surveillance?

And here are the contextual questions that provide background for the personal questions:

* What is surveillance?
* Why does privacy matter?
* How does modern surveillance work?
* How has surveillance evolved over the last few centuries?
* Why do we surveil?
* Does surveillance work?
* Who benefits from surveillance?
* Who is harmed by surveillance?
* Why are things the way they are?
* What are the key issues with surveillance?

Finally, here are the key learning objectives:

* Understand the causes and effects of surveillance, as well as the main actors
* Understand some of the technical basis of how surveillance works in personal devices and everyday life
* Go through technical exercises to increase personal privacy
* Understand how to take collective action socially and legally
* Build concrete skills in spotting surveillance infrastructure in everyday life

## How do we talk about surveillance and privacy?

Imagine you're at a dinner party with friends. Over drinks, you start talking about the news.

* "I can't believe someone hacked Tinder?! Better change my password."
* "So apparently there's been another NSA leak...."
* "Zuckerberg was definitely lying in court."
* "So I heard the NYPD uses facial recognition now?"
* "Dude remember when we talked about yogurt yesterday? I just got an ad for Dannon on Instagram today. Were they listening??"
* "In case you missed it: Russian hackers are stealing our faces!"

Sound familiar? How do you continue the conversation?

*Discuss*: Solicit candid answers from participants about media narratives of surveillance.

I'm glad we worked together to put together this list. As you know, headlines about surveillance dominate the news. When the conversation comes to surveillance, it's easy to pull out these pithy little soundbites:

* “Big brother's watching!" 
* “If you have nothing to hide, you have nothing to fear.”
* "We live in a reality TV show!"
* "We live in a real-life panopticon."
* "Privacy is dead."
* "Everyone's a voyeur."
* "Oh, I was just talking to the FBI agent in my webcam."
* "Where's my tinfoil hat?"
* "Love it when tech breaks democracy"
* "It's just like in _Black Mirror_"

Where did these soundbites come from? In most cases, nowhere in particular. But it feels like you hear them repeated everywhere. These ways of thinking are _surveillance tropes_ to watch out for. And these little slogans reinforce the message that we, as a public, feel like surveillance is something that's done to us and that we're powerless to stop. Like crabs in slowly-boiling water, we say these things so we can stop thinking about the water's rising temperature.

Our goal today is to talk about water. Let's work together to build a fresh understanding of surveillance. First, let's talk about the ways that we experience watching.

*Opening conversation*

* What brought you here today?
* Why do you care about privacy?
* Why does privacy matter?

*Facilitator prompts*

* Goal: suss out definitions of surveillance and privacy.
* Would you give me your email password and let all of us look at your email and post excerpts online?
* Why do you use the bathroom with the door shut and locked?
* Can you recall a time when you watched someone by accident?
* Can you recall a time when you felt like someone you didn't expect was watching you?
* When do you expect to be able to watch someone?
* When do you expect not to be able to watch someone?
* When do you expect someone to be watching you?
* When do you expect someone to not be watching you?

Glenn Greenwald gave a powerful defense of privacy in his talk ["Why privacy matters."](https://www.youtube.com/watch?v=pcSlowAhvUk)

> There is an entire genre of YouTube videos devoted to an experience which I'm certain everyone in this room has had. It entails an individual who, thinking they're alone, engages in some expressive behavior—wild singing, gyrating dancing, some mild sexual activity—only to discover, in fact, that they're not alone, that there is a person watching and lurking, the discovery of which causes them to immediately cease what they were doing in horror. The sense of shame and humiliation in their face is palpable. It's the sense of, 'This is something I'm willing to do only if no one else is watching.
> 
> Privacy is the "ability to go somewhere where we can think and reason and interact and speak without the judgmental eyes of others being cast upon us, in which creativity and exploration and dissent exclusively reside. And that is why, when we allow a society to exist where we are subject to constant monitoring, we allow the essence of human freedom to be severely crippled."

Now that we've talked about surveillance and privacy in the abstract, let's get more concrete. Let's talk about how we're actually being surveilled. (The following questionnaire and article are adapted from "SuperVision.")

> Are You Under Surveillance?
> Let's do a quick check. Do you have any of these?
> 
> * a cell phone
> * a credit or debit card
> * an identification card
> Do you do any of these?
> * use Google, Gmail, or Facebook
> * go to school
> * have a job
> * drive a car
> If the answer to any of these questions is yes, then you are under surveillance.

When you think surveillance, think smartphone.

> To begin rethinking your cell phone from a surveillance perspective, just imagine this (totally fake) news report: 
> 
> Washington. In legislation signed by the president, the United States government mandated that all citizens carry an electronic device providing live-streamed data on their location, communication activity, and personal interactions. Data banks will constantly record the time, duration, sender, and receiver of all telephone calls and electronic transmissions, while targeted investigations will be able to monitor actual conversations and message content. Cross-analysis of multiparty location records will show patterns of personal interaction and association. The new program also creates what one official called “300 million eyes” by requiring that each of the mandated devices be equipped with an advanced digital camera able to record and document evidence and transmit it to authorities. 
> 
> Officials from police, national security, and public health and safety agencies heralded the move. In the words of one, “This brings an end to the darkness. We can now better serve our citizens with a universal capacity to know where everyone is, all the time. We'll know who they're with, who they talk to, when they move, and where they go. This is a massive improvement in our ability to control disease, crime, and terrorism.” To offset the cost of the program, each citizen will be required to pay a monthly fee. 

Let's take this trend to the extreme. If institutions like the state and companies knew everything about us, what would they do with that information? The film "Minority Report" proposed one possible future. Here are three clips from the film:

* [PreCrime: a world with no murder](https://www.youtube.com/watch?v=oQdDLfD3kls)
* [Trailer 2 (When PreCrime goes wrong)](https://www.youtube.com/watch?v=__oEU4P_rL8)
* [The future of personalized advertising](https://www.youtube.com/watch?v=7bXJ_obaiYQ)

*Discuss*

* When do you think this film was made?
  * It was actually made 17 years ago, in 2002, when Google barely existed (it was founded in 1998) and before Twitter even existed (it was founded in 2006). The film predicted the future so well because Spielberg directed his advisors to think about the trends in *how tech was being used*.
* Would you support PreCrime?
* In what ways does the film reflect reality today, or not?

## The surveillance gap

> _We never had privacy._
> 
> _—Hamid Khan (Stop LAPD Spying Coalition)_

Even if you haven't felt it, the gaze of the state has always been a weapon aimed at reinforcing its own power.

How do you feel when you see a surveillance camera? Do you feel safe? Uneasy? A combination?
Our perception of state surveillance often surrounds heightened forms of control. This is not too far from origins of state surveillance as a counter military tactic. These systems, when turned domestically, continue to live on in the name of “national security.” In 2009, the birth of predictive policing took form from counterinsurgency tactics in Afghanistan that drew parallels between armed Afghan men and Latino youth.[^9] 

[^9]: [“We've Never Had Privacy, Hamid Khan”](https://truthout.org/video/we-ve-never-had-privacy-hamid-khan-on-how-the-surveillance-state-impacts-marginalized-communities/))

So while heightened forms of state surveillance has implications for radical work and movement building, “internalized” surveillance turns this heightened, militarized scrutiny towards “othered” populations.

In March 1713, the City of New York passed “A Law for Regulating Negro & Indian Slaves in the Night Time.” This “lantern law” required black, mixed and indigenous people—ages fourteen and older—to illuminate themselves by carrying a lit candle at night. New York City subjects were deputized to bring in any violators to the “gaols,” where they would be paid eight shillings by the offender's master. The master was authorized to perform a public whipping of forty lashes.[^10]

[^10]: [New York City has been shining surveillance lights on its black population for the last 300 years](https://splinternews.com/new-york-city-has-been-shining-surveillance-lights-on-i-1793856900)

The Lantern Law incentivized white citizens to enforce slave systems and incarceration, codifying the forms of violent, oppressive seeing that have and continue to enforce longstanding power dynamics.[^11] This early use of technology to illuminate the black and brown body applied racialized control over day-to-day mobility. The requirement to “self-illuminate” has strong parallels to the experience of “Driving While Black”—moving slowly and deliberately so a license is not mistaken for a gun, or recording all interactions with police.

[^11]: [Dark Matters: On the Surveillance of Blackness, Simone Browne](https://www.dukeupress.edu/dark-matters)

This brings up the legacy of resistance, counter-veillance, and of survival “in the dark.” Yet, what drives those living in the “surveillance gap” to that place of safety also renders them outside of services tied to systems of surveillance and control. For millions of undocumented individuals in America, the threat of deportation can prevent access to social services, education, health care, employment and housing.[^12]

[^12]:[The Surveillance Gap](https://socialchangenyu.com/review/the-surveillance-gap-the-harms-of-extreme-privacy-and-data-marginalization/#b-day-laborers))

These “terms of use” for space and services enforces a different type of control that centers access for a specific spectrum of the privileged. Those outside of that spectrum in turn are those in the most need of resources guarded by systems of power. The spectrum of “othering” creates a cycle of dehumanization, surveillance, and policing – creating the myth of the “welfare queen” and perpetuating “lazy worker” Taylorization that now govern Amazon warehouse time clocking.[^13]

[^13]: [On the Clock: What Low-Wage Work Did to Me and How it Drives America Insane, Emily Guendelsberger](https://www.goodreads.com/en/book/show/42779084-on-the-clock))

## Surveillance is different today

_Note_: The idea is to tell a parable that introduces how our notions of classical privacy must evolve to accommodate the rise of "big data," pattern recognition, and predictive technology.

### The parable of the magic room

Let's say that you had a magic room that nobody could enter. If you want to live a private life, all you have to do is go in and lock the door, and nobody can make you come out.

Let's say you're chilling in your private room, and some inspectors from the city come by and are upset that don't know what you're doing and can't get you to come out. "What could be going on behind locked doors?" they wonder, and they have to know.

If these inspectors came from before the 1900s, how might they figure out what you were doing?

_Exercise_: Ask participants how someone might surveil someone in the old days.

The inspectors would have to settle for crude, invasive ways of getting a partial picture of what you're doing in your room. 

They might spy on you with binoculars, press an ear against your door to hear what you were saying, wiretap your phone, keep records of who's coming and going from your room, intercept your letters, or shout threats at you. Basically, though, locking your door is enough to make sure that only you know what you're doing.

But what if your inspectors came from the present-day, or the future, and have all the tools of today and tomorrow at their disposal?

_Exercise_: Ask participants how someone might surveil someone today, or in the near or far future.

The first thing the neo-inspectors do is to set up sensors all over the outside of your room, to capture, in a continuous stream, any kind of audio, video, thermal, or seismic information that's leaking. So if they see slight vibrations on the seismograph, they can guess that you're probably going downstairs, or doing jumping jacks. 

Not only that, but they've actually already been capturing information about you all your life from _before_ you locked yourseif in a room, so they already know that, say, you always wake up around 9 am and have a coffee, and if your voice sounds a certain way, then you're more likely to be saying a certain thing.

Not only that, but they know lots of things about, historically, the patterns of how people have behaved when they locked themselves in rooms, people similar to you in many ways. They have records of hermits dating back from centuries, and they know what kinds of movement patterns mean that people in locked rooms are doing certain things—what patterns ultimately translated to "this person was trying to communicate in secret" and what patterns ultimately translated to "this person was just taking a nap."

Not only that... but they've already run many experiments on people who locked themselves in rooms, recorded their psychological profiles, and figured out what kinds of carrots to dangle to entice people to come _out_ of rooms without them knowing it.

Using all this context, your neo-inspectors do two things:

First, using all the information about you that's leaking out of your room about what you're currently doing, they cross-reference it with their past knowledge about you (pre-room) as well as their knowledge of hermits throughout the ages, and they can guess *what you're doing now* and predict *what you might do next*. For example, right now the seismograph is recording a strong vibration while your voice intensity spikes, so you're likely to be yelling at the TV, and the most likely thing you'll do next is throw your dinner at the TV.

Next, they cross-reference your profile with the behavioral experiments, which tells them just what to do to get you out of the room. This is about the time that you'll get hungry, and unfortunately you've already thrown your dinner at the TV. So if they waft in some subtly delicious brunch aromas through the air circulation system of your room, then you'll likely get really hungry and irrationally poke your head out the door, at which point the inspectors will grab you.

_Exercise_: Discuss how this story corresponds to real life.

### Locking doesn't stop leaking

Things used to be so easy. Locking your "digital" door _used_ to be enough. You could create strong "locks" for every site, as well as use strongly "locked" channels for your communications, and know that only you knew what you were doing. And for the same reasons above, classical security is no longer a defense against being surveiled!

Why? Because _data is power._ The sum of all the information about a person forms a "data double" of the person, and the digital nature of life means that more and more data about a person's life can be recorded. As the _New York Times_ puts it, "data is always flaking off us like dead skin cells." Even if you were completely off the grid, someone could learn a lot about you by surveiling all of your friends and family. Using all that data, many weak observations about a person can be combined to make very strong judgments and predictions about them that can be used to change the way they behave without them knowing about it.

TODO: Discuss how this trend is not new; it is an acceleration of how technologies of recording/biometrics/legibility have been historically deployed on disadvantaged groups, like early forms of biometrics used on enslaved Africans

TODO: Discuss how methods of defense are evolving beyond "classical" privacy: defensive (e.g. data collection, retention, cookie policies); offensive (e.g. polluting data with noise; developing disobedient technologies); neutral (requiring reporting; security through obscurity)

TODO: make all the examples a lot more concrete

TODO: run this explanation by an ML person to make sure it's reasonably accurate

### Tomorrow's surveillance, today

> _The future is already here; it's just not evenly distributed._
> 
> _—William Gibson_

Now that we've discussed the parable of data, how do these practices—that of data-powered state and corporate surveillance—manifest in the world today?

(TODO: this is old writing; need to merge with the above section and simplify the language)

In Guiyang, the police found a BBC reporter using the city's facial-recognition-powered surveillance system in seven minutes. (See BBC video: [In your face: China's all-seeing state](https://www.bbc.com/news/av/world-asia-china-42248056/in-your-face-china-s-all-seeing-state)) What technical, social, and legal infrastructure made this achievement possible? And what are the civil liberties issues with pervasive surveillance?

First, physical infrastructure manifests itself as the familiar "eyes of big brother": surveillance cameras. Behind the scenes, IP cameras rely on internet infrastructure. 

Second, everything that can be turned into data will be turned into data: for example, Google Street View, the government's "multiple encounter deceased" dataset for facial recognition, and scraping millions of Flickr photos online. "If you're an adult in America, there's more than a 50 percent chance that you're already in a law enforcement facial recognition database, according to researchers at Georgetown." (Source: NYT [Facial Recognition Machine](https://www.nytimes.com/interactive/2019/04/16/opinion/facial-recognition-new-york-city.html))

Third, large-scale AI works by humans encoding community knowledge and norms. When you do a captcha or submit a Google form, you are helping train, say, a self-driving car to recognize what's a car and what's a road sign. Dataset labeling factories are becoming increasingly common (again, Guiyang, China is the frontier). (See _Sixth Tone_ article and video: [Tilling the data farms of Guizhou](http://www.sixthtone.com/news/1002222/tilling-the-data-farms-of-guizhou)) These dataset labeling factories use people for their "minimum viable humanity" to extract and capture their value for the profit of the very few.

What happens after dataset labeling? Since humans label data, it encodes community knowledge and biases. For example, in facial recognition, datasets are labeled with one of few emotions. Modern models learn to map an input (a picture of a face) to an output (an emotion label) by a process of learning from their mistakes over and over on a dataset spanning millions or billions of examples. Then a trained emotion detection model might be deployed in, say, a surveillance camera to recognize anomalies in public space, for example if a person looks fearful or angry, it might make a decision to call police. Again, note that your ML algorithm is limited by your dataset! The result is that old instruments for looking and capture become lenses augmented by massive data and compute to encode certain ways of looking, and to enforce these norms on public space, like Esther Hovers' series "False Positives."

Who's being looked at? People and their faces and bodies are constantly being analyzed and dissected by algorithms. Your faceprint is everywhere. Facebook image labeling, unlocking your phone.

Who's looking? Other people. Often not the people you expect. Voyeurs in the NYPD; your neighbors; hackers in another country; and you. The gaze becomes a part of you, something you carry around inside you.

Lastly: follow the money! Surveillance is big business. China's biggest facial recognition startups, Dahua and Hikvision, are worth billions[^money]. (TODO: discuss why)

[^money]: ["US Universities And Retirees Are Funding The Technology Behind China's Surveillance State"](https://www.buzzfeednews.com/article/ryanmac/us-money-funding-facial-recognition-sensetime-megvii)

### Experience-based exercises

* Start by looking at examples of ML in people's personal devices. These are (mostly-frivolous) consumer applications, like Snapchat's gender swap, Apple's emoji facematch, or Alexa's voice recognition, but give people an idea of how to identify ML in real life.
* From [_A People's Guide to AI_](https://www.alliedmedia.org/peoples-ai): do a simple exercise in predicting people's behavior (page 53)
* How does machine learning work? Train a classifier live, in the browser, using [Teachable machine](https://teachablemachine.withgoogle.com/).
* Explore facial recognition and its biases: try DSSG software
* [You're the AI](https://www.coveillance.org/toolkit#youre-the-ai): label photos of surveillance cameras

<!-- ### References -->

<!-- * https://www.eff.org/issues/ai -->
<!-- * https://www.eff.org/ai/metrics -->
<!-- * https://ssd.eff.org/en/module/why-metadata-matters -->

## How am I being surveilled in my daily life? Using stories to map surveillance

Let's tell some stories about your information and what happens to it. We'll use these stories as a way to make a map of how surveillance works—how all the parts fit together and the ways we can grasp how it works.

_Note_: The idea is to encourage participants to develop a shared representation of the metaphors we use to understand on surveillance. After each story, discuss what the story is meant to illustrate, what entities to add to the map, and how these entities relate to what's already on the map. Ideally everyone would have a pen and paper, and the facilitator would work on a whiteboard that everyone could see. The goal is to work together to make a map like [this one](https://www.figma.com/file/C15vnW0gtZybtY24eXREfy/Field-Guide-Prototype?node-id=75%3A0).

First, let's start with some common stories about you—how you volunteer your information and thus make yourself visible to various watchers.

_Discuss_: Solicit suggestions from participants first.

* You get an Android phone because everyone has one, or it makes life easier, or you need to get one for work.
* You join Facebook because all of your friends are there and you want to know what's happening. When you visit a new city, you post your location on Facebook so you can find friends.
* You get a Google Home because it makes life easier.
* You let your Android phone track your location in real-time, which lets you use services like Uber and Google Maps.
* You let your Apple Watch track your heart rate while running. It analyzes that data and gives you insights about trends in your health.
* You let the _Guardian_'s website store cookies in your browser, which they say lets them recommend products and serve ads that are more relevant to your interests.
* You upload a picture of your face to FaceApp or Google Art Selfie or Snapchat, which serves you a fun picture of your face (aged, or compared to a painting, or gender-swapped) which you send to your friends.
* You let a TSA agent scan your luggage and pat you down at the airport.

_Note_: These stories are picked to be more approachable because they illustrate voluntary surveillance (or self-surveillance) via the consumer-tech entities that most participants should be familiar with. Use the opportunity to introduce a visual grouping for "You" and another one for platform companies (the surveillance capitalists). Also, discuss how "You" become visible to the watchers through your data.

These are all examples of _voluntary_ surveillance: you know what information you're giving out. Now let's discuss some other stories about surveillance—some you might not have experienced, some about surveillance under duress, using information you didn't consent to giving up, using processes opaque to the people caught up in them. They are all real stories or composites of real stories.

_Discuss_: Solicit suggestions from participants first.

* You log on to Facebook and take a personality quiz. It tells you you're an INTJ. Later, you see some pretty good ads for a local congressional candidate, and decide to learn more about them.

_Note_: This is an entry point to this whole story that people should have vaguely heard of: ["The Data That Turned the World Upside Down: How Cambridge Analytica used your Facebook data to help the Donald Trump campaign in the 2016 election."](https://www.vice.com/en_us/article/mg9vvn/how-our-likes-helped-trump-win ) The point is to introduce a relationship between private entities and public entities, to introduce the idea of public-private collusion, and to introduce the idea of many small pieces of information being used for a much huger emergent purpose (i.e. that of undermining democracy).

* You search for baby formula on Google, then visit Target's site. They send you mail with a coupon that reads "Congratulations on the baby!" You're still living with your parents, who are Puritans who you were trying to keep a secret from. They kick you out of the house. 

_Note_: This is the famous ["Target knows you're pregnant before your parents do"](https://slate.com/human-interest/2014/06/big-data-whats-even-creepier-than-target-guessing-that-youre-pregnant.html
) story. It serves as an entry point to surveillance capitalism and predictive behavior influencing.

* You have an Android phone and you go about your daily life. The Feds issue a geofence warrant to Google to get your location data. They suspect you of murder and arrest you based on the data.

_Note_: This is another pathway to public-private collusion, as well as discussing data storage/longevity issues and issues of scope creep. [NYTimes article](https://www.nytimes.com/interactive/2019/04/13/us/google-location-tracking-police.html?action=click&module=privacy%20belt%20recirc%20module&pgtype=Article)

* You're out with your family and you take a bunch of nice photos, which you upload to Flickr. An IBM researcher scrapes your photo from Flickr and uses it to train a facial recognition model, technology that it sells to the NYPD so it can “search CCTV feeds for people with particular skin tones or hair color.”

_Note_: This is an entry point to the role of facial recognition and AI in surveillance in the US, how surveillance is targeted at marginalized groups of people, and how personal data is collected coercively to fuel private gain.
[NBC article](https://www.nbcnews.com/tech/internet/facial-recognition-s-dirty-little-secret-millions-online-photos-scraped-n981921)

* You live in San Francisco, and you spend a nice day out at the Brainwash cafe. Unbeknownst to you, the camera in the cafe recorded your face. Stanford researchers tap into the camera installed in the cafe and grab all the face images to create a dataset, which is then used in China by to develop surveillance technology for monitoring and persecuting ethnic minorities.

_Note_: [This story](https://www.nytimes.com/2019/07/13/technology/databases-faces-facial-recognition-technology.html
) reinforces the above story about facial recognition and targeting minorities, adds the nuance that data can move outside state boundaries, and is an entry point to the advanced Chinese surveillance state.

* You share a candlelit dinner with your partner at home. Your Alexa device records the audio of your conversation and sends it offshore for workers to transcribe. The transcription is used to improve Alexa's voice recognition technology.

_Note_: This story introduces another corporate actor, Amazon, as well as personal hardware, and the coercive nature of modern AI.
[Accidental recording](https://www.npr.org/sections/thetwo-way/2018/05/25/614470096/amazon-echo-recorded-and-sent-couples-conversation-all-without-their-knowledge), [audio review team](https://www.bloomberg.com/news/articles/2019-04-10/is-anyone-listening-to-you-on-alexa-a-global-team-reviews-audio)

* You're out with your friends downtown. A beacon tracks your location and knows that you went to Dick's Sporting Goods at 2 pm, to the mall at 3 pm, to the bathroom at 4 pm, and that you hesitated in front of a Doc Martens store but didn't go in. The next day, while reading the news, you see a bunch of ads for Doc Martens and decide to go back to the store.

_Note_: This story is an entry point to ongoing corporate surveillance in physical space and how it ties into advertising and behavioral  microtargeting. It also reinforces how much information a smartphone can leak: Bluetooth beacons and MAC address trackers can ping your phone, identifying your location and identity. This story can lead into an exercise about wifi network inspection.
[Bluetooth tracking](https://www.nytimes.com/interactive/2019/06/14/opinion/bluetooth-wireless-tracking-privacy.html?rref=collection%2Fseriescollection%2Fnew-york-times-privacy-project), [This trash can is stalking you](https://arstechnica.com/information-technology/2013/08/no-this-isnt-a-scene-from-minority-report-this-trash-can-is-stalking-you/), EFF's [Why Metadata Matters](https://ssd.eff.org/en/module/why-metadata-matters)

* You're out on the roof with your partner at night, enjoying a warm and intimate evening. Nobody can see you here, right? Unbeknownst to you, a man in an NYPD helicopter is using thermal imaging to spy on you.

_Note_: This story is taken straight from the [New York Times](https://www.nytimes.com/2005/12/22/nyregion/police-video-caught-a-couples-intimate-moment-on-a-manhattan.html
). It introduces the human element of surveillance: misuse of the state surveillance apparatus—ostensibly for your protection—for a human observer's voyeuristic glee, even in a place that should be secret.

* You drive around the city to several destinations: to work, to dinner, to your partner's place. Your license plate is recorded by every license plate reader you pass on the way and your laptop's unique identifier (called a MAC address) is recorded by every Acyclica device you pass along the way. This data is stored by private and public entities (both the city and the companies that manufacture these devices) and sent to quasi-private entities for analysis, like Palantir. One possible fate is that, if you are in the US as a migrant, the city might share your location data with ICE, which uses your location info to find and deport you. 

_Note_: [This story](https://www.aclunc.org/blog/documents-reveal-ice-using-driver-location-data-local-police-deportations) is an entry point to state surveillance and starts to introduce some of the technology that we'll visit in the walking tour. It also reinforces the relationship between public and private actors, and introduces two main problems with pervasive surveillance, namely scope creep and data retention.

* You are a US citizen on US soil. While writing a paper, you visit the website of an academic collaborator in Britain, who (unbeknownst to you) is alleged to be a terrorist suspect. Your request for the webpage passes through your internet service provider, then through an AT&T peering center, where it is intercepted by an NSA wiretap, copied to Maryland, and caught in the XKEYSCORE software by an NSA analyst. This piece of information just about tips the scales of a predictive algorithm to land you on a no-fly list. You only find out when you try to fly to a conference to give an invited talk and you're stopped at the airport. There is no appeal or recourse for your status on the no-fly list.

_Note_: This story is by necessity a collage of several stories, since we know so little about the inner workings of the NSA and the no-fly list—it's a "matter of national security." Nevertheless, based on the sources below, it seems plausible. This story is an entry point to several broader themes: the policy of the Foreign Intelligence Surveillance Act that the NSA should limit wiretapping to non-US citizens, and its ability to circumvent this policy to spy on US citizens if a foreign national is involved; data fusion; the deep opacity and arbitrary nature of state surveillance and automated decision systems; public-private information sharing; the dragnet nature of surveillance; and the very frustrating and hurtful effects the combination of these factors can have on an individual. It's also a counterpoint to the "nothing to hide, nothing to fear" argument—you have nothing to hide, you would have no problem revealing your list of academic collaborators, and you've done nothing wrong; it's only the "guilt by association" argument that brings the hammer crashing down. We will also see an AT&T peering site on the walking tour. 
[No-fly list predictive assessments](https://www.theguardian.com/us-news/2015/aug/10/us-no-fly-list-predictive-assessments), [NSA spying on US citizens](https://thehill.com/opinion/national-security/429770-8-surprising-times-our-intel-community-spied-on-us-citizens)

## Metaphors for surveillance

We've discussed many stories about our information. We've seen how it can be used to make life more convenient. We've also seen how it can be used in ways we didn't expect—against us, against others, or for other' profit. Now, let's talk about how it all fits together in the map we've made.

*Discuss*: Talk about the map the partipants made together, as well as visual metaphors for surveillance.

Here is one possible way to map the anatomy of surveillance.

<img src="media/anatomy-of-surveillance.png" width="550">

You can find the high-resolution image [here](https://www.figma.com/file/C15vnW0gtZybtY24eXREfy/Field-Guide-Prototype?node-id=75%3A0).

One metaphor for understanding surveillance is that it's a huge octopus with many arms, with the public being many tiny fish, and your personal data being like air bubbles. The octopus siphons up the data with surveillance infrastructure, both digital and physical, and transmits it over the network to a cast of watchers, including those who watch for profit (the surveillance capitalists), those who watch for law enforcement (the state), and various organizations, quasi-private institutions, and individuals. All the information gathered is pooled, collated, stored, mined for insight, and used to influence and regulate the behavior of the public.

Another metaphor for understanding surveillance is that of the *surveillant assemblage*. There's no big brother, no single watcher, no one panopticon. Instead, the assemblage flattens an individual into portable data and takes bits of pieces of them into different contexts they never expected. It consists of the "shifting, moving observation presentation, and regulation of the self by countless measures in countless locations." The smartphone is the prime icon of the surveillant assemblage.

Let's get some fresh air and make this real: let's go see some surveillance infrastructure in real life.

*Exercise*: Conduct the [surveillance infrastructure walking tour.](http://www.coveillance.org/tour.html)

After returning from tour:

Why are things the way they are? Consider a thought experiment. What's something you've always wondered about someone, or a group of people? What if you could read your partner's emails? What if you could read the diary of your worst enemy? What if you could know anything you wanted about a person or a group of people—for example, how many people in the United States are awake at this very moment? How many people in the United States just got off work and are hungry for dinner? If you could know literally anything you wanted, would you want to know, and what would you want to know? Conversely, if you know that others could know literally anything they wanted, how would you want them to be able to know you?

Now you understand the impulse to surveil. We live in an information-seeking society, where government, industry, religion, and social life are all driven by the desire to measure and compare every aspect of life. Everyone wants to know more, and the more you can know, the more you expect to be known and to know.

As "SuperVision" puts it:

> Today's organizations both require and create orderly, systematic knowledge about the people and things they govern or manage. Surveillance is in the DNA of the modern organization. Businesses, governments, universities, even individuals, seek to gather and organize information as an ongoing part of their work. It's simply part of what we're expected to do as responsible actors. Think about how many of our contemporary ideologies or value systems celebrate unfettered access to information. Science must have its data. Law must have its witnesses and confessions. Religion has its all-knowing deities. Democracy has its transparency. Rationality must have its perfect information. They all want to know more! This is a unique cultural alignment in which our key value systems unite to push us toward the celebration and advancement of surveillance as a means of social organization and control. In the face of this level of government, corporate, and ideological convergence in favor of advancing surveillance, we are skeptical that the flood can be pushed back. But we might be able to make it a bit more fair, transparent, and accountable.

## Taking action

So, what can we do about surveillance? And what can _you_ do about surveillance?

First, I would suggest arming yourself against the soundbites we identified in the beginning. The next time someone pulls out that old saw "If you have nothing to hide, nothing to fear" at a party or in a debate, or someone (perhaps a lawmaker, perhaps the CEO of Google, perhaps your best friend) frames surveillance as inevitable, remember some of the many social and civil liberties issues with surveillance:

* General creepiness
* Imbalance of power between watcher and watched
* Inability to opt out
* Unanticipated data fusion and collation
* Coercive nature of data-gathering
* Data longevity
* Scope creep
* Shifting terrain
* Chilling effect on freedom of speech and association
* Unclear policies
* Lack of accountability
* Others making money off your identity and experience
* Influencing your behavior
* Amplifying social bias
* Targeted at marginalized groups
* As a security measure, it's largely ineffective
* Insecure system
* Lack of transparency
* Hierarchical and undemocratic
* Expensive compared to alternative analog solutions

You can find a great dossier of surveillance technologies and their civil rights issues at the ACLU's [They Are Watching](http://theyarewatching.org/) page. 

To change the state of things, take collective social action: work to raise expectations for the protection of personal data, expect to be able to opt out instead of opt in, keep information in its original context, and fight for transparency in a system. You can spearhead or lead legal efforts, for example to ban facial recognition or regulate surveillance technologies. The EFF has put together a great dossier of [countersurveillance success stories](https://www.eff.org/csss).

You can also take concrete technical steps to protect yourself against surveillance, ranging from doing a periodic privacy checkup (just like going to the doctor for a yearly checkup), adopting more secure software and hardware, adopting more private practices, and learning the technical details about how surveillance works. We've included some suggestions in the [Exercises](#exercises) section.

Knowledge is power. Stay informed about the uses and abuses of surveillance with the following resources:

* [SuperVision: an introduction to the surveillance society](https://socialandmobilemedia.files.wordpress.com/2017/02/supervision.pdf)
* [Big other: surveillance capitalism and the
prospects of an information civilization](https://cryptome.org/2015/07/big-other.pdf)
* [Dark matters: on the surveillance of blackness](https://www.dukeupress.edu/dark-matters)
* [The NYTimes Privacy Project](https://www.nytimes.com/series/new-york-times-privacy-project)
* [The Intercept](https://theintercept.com/)'s privacy and surveillance coverage
* [Citizenfour](https://citizenfourfilm.com/)

Finally: take the time to interrogate your own urge to know, and how it's enabled by the society we live in.

### If you just want to do ONE thing...

Try out this handy tool for helping you decide on the best action to take right now:

<img src="media/action-decision-tool.png" width="600">

(You can see the full-size version [here](https://www.figma.com/file/C15vnW0gtZybtY24eXREfy/Field-Guide-Prototype?node-id=263%3A2).)

_Note:_ This tool is our start at overcoming decision paralysis and answering the question: "if I could do only ONE thing, what's the best thing for me to do?" Ideally, in the future, this might be an interactive tool, like a Buzzfeed quiz, that would take into account the person's age, knowledge level, interests, time, etc. to suggest concrete social/technical avenues for action, and to suggest good exercises for them to do in this material.

### Performing sousveillance

TODO: Discuss ways to enact a critical or disobedient gaze, and to reverse the gaze.

<!-- Activists have proposed the idea of sousveillance to reverse the gaze, notably Simone Browne's "Dark Matters." Artists and academica have made attempts at mapping surveillance networks, controlling them with legislation or agreements, jamming them with individual actions.  -->

_Closing conversation_

* How has your understanding of surveillance changed during the last few hours, if at all?
* Discuss opportunities to provide public comment on the [Seattle Surveillance Ordinance](http://www.seattle.gov/tech/initiatives/privacy/surveillance-technologies/about-surveillance-ordinance) and take action with the ACLU WA
* How do you want things to change?

## Exercises

_Note: These are proposed exercises: let us know which ones you find most compelling._

### Cookie monster

Look at tracking cookies in Chrome. People open their desktop browsers and visit the URL _chrome://settings/siteData?search=cookies_. They can see the unique identifying strings that websites and ad networks use to track their identity across several site visits. Accompany the exercise with illustrations from [How does online tracking actually work?](https://robertheaton.com/2017/11/20/how-does-online-tracking-actually-work/).

### You're the AI

Label the dataset of surveillance camera images that you gathered on the walking tour. See [A field guide to spotting surveillance cameras](http://www.coveillance.org/camera-spotting) for more information.

_Discuss_

* How AI depends on the human element
* What if you labeled things incorrectly?

### Privacy checkup

(TODO: write out exercises)

* Try the Jumbo app to do a privacy audit of your social media services.
* Block tracking online: use Adblock and Ghostery.
* Periodically clear your cookies and browsing history.
* Use secure email and communications such as Protonmail, Signal, or PGP.
* Use a privacy-focused search engine like DuckDuckGo.
* Use an iPhone instead of an Android phone.
* Lock down your location on your phone.
* Audit your authorized services on platforms like Facebook, Google, and Twitter.
* Use a password manager.
* Use the most restrictive settings on your smart home (e.g. turn off voice recording).
* Turn off your auto-wifi joining.
* Don't join public wifi.
* Make sure your browsing is locked down: look for HTTPS (the lock icon in the browser).
* Serious privacy aficionados might use a secure OS like Tails or a secure browser like Tor, but be aware that this practice (unfortunately) might get you targeted.

### In someone else's shoes

See a dashboard of all the things you are sharing publicly. 
A ML algorithm (created by us) will display:

* Most common results
* Inferred demographics (if possible)

_Discuss_

* Did you realize this information was public?
* What are your expectations around public information? (For example, someone could use your picture and pretend to be you. Would you expect that?)

### What do tech companies know about you?

Same as "In someone else's shoes" but we will display and use their location data, search terms, FB posts shared only to friends, contacts, etc.

### You are now a tech company

You're given an example corpus of data with example search terms. You have a list of things/advertisements to sell. Work together to determine who to target those ads to.

_Discuss_

* How did you make the decisions?
* What was your goal? What was your attitude towards the individual whose data you were looking at?

### Terms of Service

Two-part activity

* Display a fake ToS as part of our app that asks them to consent
  * Our fake ToS contains humorous/egregious comments, e.g., consenting to sell your soul
  * Takeaway: People don't really read ToS
* Dissect Google's ToS and see what you are really consenting to

### WiFi Guess Who

The MAC addresses and corresponding WiFi network names are gathered via custom software (to be built by the sousveillance collective). Participants will work together as a group to match MAC addresses to the real-life person, in a game of Guess Who.

Possible rules of the game:

* Participants cannot identify themselves. Otherwise, it might be too easy as they know their home network names.
* Participants can ask each other questions, e.g., “Who here works for Amazon?”
* To encourage equal participation, possibly have participants sit in a circle and pass around an object (the person holding the object gets to speak / ask questions). 
* Participants may opt out if they wish by turning their phones on airplane mode.

Important: WiFi network names can contain sensitive data! (Imagine a participant who has connected to “dr_brown_psychiatry” or “seattle_strip_club”). The participant may not even realize that this may be revealed. To prevent this, before the start of the game, ask participants to view the list of networks that their device tries to connect to. They can remove any networks that are sensitive, but encourage them not to remove identifying but unembarrassing networks (e.g., “SFO airport”).

#### Example walkthrough

The example data has been gathered:

```
00:0a:95:9d:68:16    xfinity
00:0a:95:9d:68:16    park94
09:11:55:3d:22:11    AshZResidence
09:11:55:3d:22:11    13th St Starbucks Free WiFi
11:a0:c9:14:c8:29    Amazon-Work
11:a0:c9:14:c8:29    LAX Boingo
```

The facilitator can give a short introduction to what a MAC address is (link to field guide WiFi surveillance chapter).

The facilitator may start off with some questions:

* What types of identifying information can be spotted?
* Is there anyone who can be identified right away? (For example, “Jay Park” must be the person who connects to “park94”).

If the group is stuck, the facilitator can:

* Help them think outside the box:
  * What regions of Seattle are supported by Xfinity (an internet provider)? Can this help narrow down people based on where they live?
* Pivot the discussion by examining what information is missing or how information was obscured, to prevent identification
  * What kind of WiFi network names obfuscated identities in this exercise?
  * Even if you couldn't identify someone, what information were you able to gather about that person? How could this information be used by [an advertiser, the government, a company, a malicious person]?

If the group unable to identify everyone, that's okay! The facilitator can talk about other ways to identify someone, such a driving past someone's house and seeing the same MAC address at that location. 
They can also discuss how this information can be used to violate people's privacy, such as location tracking
It can also be a good segue into a discussion about location tracking and Acyclica [TODO].

If the group is interested or more advanced technologically, the facilitator can examine packets that are captured [TODO].

### WiFi safari

Participants join a local network that the facilitator sets up. The group observes the network traffic, e.g. the MAC addresses and packet snippets.

Possibly, with a bigger group, replicate Acyclica

  * Split up into smaller groups.
  * See if there are any MAC address repeats. What does that tell you about that person? 

</div>

</div>

<script
  src="https://code.jquery.com/jquery-3.4.1.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
	  crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
<script src="lib/jquery.sidenotes.js"></script>

<script>
 $(() => {
     console.log("ready");

     tocbot.init({
	 // Where to render the table of contents.
	 tocSelector: '.js-toc',
	 // Where to grab the headings to build the table of contents.
	 contentSelector: '.js-toc-content',
	 // Which headings to grab inside of the contentSelector element.
	 headingSelector: 'h1, h2, h3',
	 // For headings inside relative or absolute positioned containers within content.
	 hasInnerContainers: true,
     });

     $(".footnotes").appendTo(".all-content");

     /*      $('.all-content').sidenotes();*/
 });
</script>
